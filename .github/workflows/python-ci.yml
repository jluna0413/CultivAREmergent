name: Python CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'
  POSTGRES_USER: postgres
  POSTGRES_PASSWORD: postgres
  POSTGRES_DB: cultivar_test

jobs:
  # Job 1: Linting and Static Analysis
  lint:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-lint-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-lint-
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements_fastapi.txt
          pip install flake8 pylint black isort mypy

      - name: Run Flake8 linting
        run: |
          # Stop the build if there are Python syntax errors or undefined names
          flake8 app/ --count --select=E9,F63,F7,F82 --show-source --statistics
          # Exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
          flake8 app/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Run Pylint analysis
        run: |
          pylint app/ --fail-under=7.0 --exit-zero

      - name: Check code formatting with Black
        run: |
          black --check app/

      - name: Check import sorting with isort
        run: |
          isort --check-only app/

  # Job 2: Database Setup and Migrations
  database:
    name: Database Migration Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}
          POSTGRES_USER: ${{ env.POSTGRES_USER }}
          POSTGRES_DB: ${{ env.POSTGRES_DB }}
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements_fastapi.txt
          pip install alembic psycopg2-binary

      - name: Run Alembic migrations
        env:
          DATABASE_URL: postgresql://${{ env.POSTGRES_USER }}:${{ env.POSTGRES_PASSWORD }}@localhost:5432/${{ env.POSTGRES_DB }}
        run: |
          # Create database schema from scratch
          alembic upgrade head
          echo "‚úÖ Database migrations applied successfully"

      - name: Test Alembic downgrade
        env:
          DATABASE_URL: postgresql://${{ env.POSTGRES_USER }}:${{ env.POSTGRES_PASSWORD }}@localhost:5432/${{ env.POSTGRES_DB }}
        run: |
          # Test that downgrades work correctly
          alembic downgrade -1
          echo "‚úÖ Database downgrade test passed"

      - name: Verify migration integrity
        env:
          DATABASE_URL: postgresql://${{ env.POSTGRES_USER }}:${{ env.POSTGRES_PASSWORD }}@localhost:5432/${{ env.POSTGRES_DB }}
        run: |
          # Re-apply migrations to ensure consistency
          alembic upgrade head
          alembic current
          alembic history --verbose
          echo "‚úÖ Migration integrity verified"

  # Job 3: Unit Tests
  test:
    name: Unit Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}
          POSTGRES_USER: ${{ env.POSTGRES_USER }}
          POSTGRES_DB: ${{ env.POSTGRES_DB }}
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-test-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-test-
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements_fastapi.txt
          pip install pytest pytest-asyncio pytest-cov httpx

      - name: Run unit tests
        env:
          DATABASE_URL: postgresql://${{ env.POSTGRES_USER }}:${{ env.POSTGRES_PASSWORD }}@localhost:5432/${{ env.POSTGRES_DB }}
          SECRET_KEY: test-secret-key-for-ci
          FRONTEND_ORIGINS: http://localhost:3000,http://localhost:8000
          ALLOWED_HOSTS: localhost,127.0.0.1
          ENVIRONMENT: testing
        run: |
          pytest tests/ -v --cov=app --cov-report=xml --cov-report=html --cov-fail-under=80

      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

  # Job 4: OpenAPI Schema Generation and Snapshot Testing
  openapi:
    name: OpenAPI Schema Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history for comparison

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements_fastapi.txt

      - name: Generate OpenAPI specification
        env:
          FASTAPI_SKIP_ROUTERS: "1"
          DATABASE_URL: postgresql://${{ env.POSTGRES_USER }}:${{ env.POSTGRES_PASSWORD }}@localhost:5432/${{ env.POSTGRES_DB }}
          SECRET_KEY: test-secret-key-for-ci
        run: |
          python scripts/generate_openapi.py

      - name: Verify OpenAPI schema generation
        run: |
          if [ ! -f "docs/generated/openapi.json" ]; then
            echo "‚ùå OpenAPI schema generation failed"
            exit 1
          fi
          
          echo "‚úÖ OpenAPI schema generated successfully"
          echo "Schema size: $(wc -l < docs/generated/openapi.json) lines"

      - name: Validate OpenAPI schema structure
        run: |
          python3 -c "
          import json
          import sys
          
          with open('docs/generated/openapi.json', 'r') as f:
              schema = json.load(f)
          
          # Basic validation
          assert 'openapi' in schema, 'Missing openapi version'
          assert 'info' in schema, 'Missing info section'
          assert 'paths' in schema, 'Missing paths section'
          
          paths = schema.get('paths', {})
          print(f'‚úÖ OpenAPI schema valid with {len(paths)} endpoints')
          
          # Show endpoint summary
          for path in sorted(paths.keys())[:10]:
              methods = list(paths[path].keys())
              print(f'  {path} ({", ".join(methods)})')
          if len(paths) > 10:
              print(f'  ... and {len(paths) - 10} more')
          "

      - name: Check for OpenAPI schema changes
        id: openapi-changes
        run: |
          # Check if OpenAPI schema has changed compared to main branch
          if git diff --quiet docs/generated/openapi.json; then
            echo "status=unchanged" >> $GITHUB_OUTPUT
            echo "‚úÖ OpenAPI schema unchanged - no regressions detected"
          else
            echo "status=changed" >> $GITHUB_OUTPUT
            echo "‚ùå OpenAPI schema has changed!"
            echo ""
            echo "Changes detected:"
            git diff docs/generated/openapi.json | head -100
            echo ""
            
            # Count changes
            additions=$(git diff --unified=0 docs/generated/openapi.json | grep -c '^+' || echo "0")
            deletions=$(git diff --unified=0 docs/generated/openapi.json | grep -c '^-' || echo "0")
            echo "Changes summary: +${additions} additions, -${deletions} deletions"
            
            echo "This indicates potential API regressions or intentional changes."
            echo "Please review the changes and update the snapshot if intentional."
          fi

      - name: Comment PR with OpenAPI changes
        if: github.event_name == 'pull_request' && steps.openapi-changes.outputs.status == 'changed'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            
            let comment = '## ‚ö†Ô∏è OpenAPI Schema Changes Detected\n\n';
            comment += 'The OpenAPI schema has been modified. This could indicate:\n';
            comment += '- API regressions during migration\n';
            comment += '- Intentional API changes\n';
            comment += '- Documentation updates\n\n';
            comment += 'Please review the changes:\n\n';
            comment += '```diff\n';
            
            const { execSync } = require('child_process');
            const diff = execSync('git diff docs/generated/openapi.json', { encoding: 'utf-8' });
            comment += diff;
            comment += '```\n\n';
            comment += '**Action Required:** If these changes are intentional, update the OpenAPI snapshot by committing the changes.\n';
            comment += 'If unintended, investigate and fix the regression.\n';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Upload OpenAPI schema
        uses: actions/upload-artifact@v3
        with:
          name: openapi-schema
          path: docs/generated/openapi.json

  # Job 5: Integration Tests
  integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [database, test]
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}
          POSTGRES_USER: ${{ env.POSTGRES_USER }}
          POSTGRES_DB: ${{ env.POSTGRES_DB }}
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements_fastapi.txt
          pip install pytest httpx alembic psycopg2-binary

      - name: Setup test database
        env:
          DATABASE_URL: postgresql://${{ env.POSTGRES_USER }}:${{ env.POSTGRES_PASSWORD }}@localhost:5432/${{ env.POSTGRES_DB }}
        run: |
          alembic upgrade head

      - name: Start FastAPI application
        env:
          DATABASE_URL: postgresql://${{ env.POSTGRES_USER }}:${{ env.POSTGRES_PASSWORD }}@localhost:5432/${{ env.POSTGRES_DB }}
          SECRET_KEY: test-secret-key-for-integration
          FRONTEND_ORIGINS: http://localhost:3000
          ALLOWED_HOSTS: localhost,127.0.0.1
          ENVIRONMENT: testing
        run: |
          # Start FastAPI app in background
          uvicorn app.fastapi_app:app --host 127.0.0.1 --port 8000 &
          echo $! > fastapi.pid
          
          # Wait for app to start
          echo "Waiting for FastAPI app to start..."
          timeout 60 bash -c 'until curl -f http://127.0.0.1:8000/health; do sleep 1; done'
          
          echo "‚úÖ FastAPI application is running"

      - name: Run API Health Checks
        run: |
          echo "Testing API health endpoints..."
          
          # Basic health checks
          curl -f http://127.0.0.1:8000/ || exit 1
          echo "‚úÖ Root endpoint working"
          
          curl -f http://127.0.0.1:8000/health || exit 1
          echo "‚úÖ Health endpoint working"
          
          curl -f http://127.0.0.1:8000/ping || exit 1
          echo "‚úÖ Ping endpoint working"
          
          curl -f http://127.0.0.1:8000/api/v1/system/info || exit 1
          echo "‚úÖ System info endpoint working"

      - name: Run integration tests
        env:
          TEST_BASE_URL: http://127.0.0.1:8000
          DATABASE_URL: postgresql://${{ env.POSTGRES_USER }}:${{ env.POSTGRES_PASSWORD }}@localhost:5432/${{ env.POSTGRES_DB }}
        run: |
          pytest tests/integration/ -v --tb=short

      - name: Test API endpoints manually
        run: |
          # Test key API endpoints
          BASE_URL="http://127.0.0.1:8000"
          
          echo "Testing Plants API..."
          curl -f "${BASE_URL}/api/v1/plants" || echo "Plants API test skipped (may require auth)"
          
          echo "Testing Strains API..."
          curl -f "${BASE_URL}/api/v1" || echo "Strains API test skipped (may require auth)"
          
          echo "Testing Auth endpoints..."
          curl -f "${BASE_URL}/auth/docs" || echo "Auth docs endpoint working"

      - name: Stop FastAPI application
        if: always()
        run: |
          if [ -f fastapi.pid ]; then
            kill $(cat fastapi.pid) || true
            rm fastapi.pid
            echo "‚úÖ FastAPI application stopped"
          fi

  # Job 6: Security and Performance Tests
  security:
    name: Security & Performance
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request' || github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install bandit safety semgrep

      - name: Run Bandit security linter
        run: |
          bandit -r app/ -f json -o bandit-report.json || true
          bandit -r app/ || true

      - name: Check dependencies for vulnerabilities
        run: |
          safety check --json --output safety-report.json || true
          safety check || true

      - name: Run Semgrep
        run: |
          semgrep --config=auto app/ --json --output=semgrep-report.json || true
          semgrep --config=auto app/ || true

      - name: Upload security reports
        uses: actions/upload-artifact@v3
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json
            semgrep-report.json

  # Job 7: Build and Package
  build:
    name: Build Application
    runs-on: ubuntu-latest
    needs: [lint, database, test, openapi, integration]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install build dependencies
        run: |
          python -m pip install --upgrade pip
          pip install build twine

      - name: Build package
        run: |
          python -m build

      - name: Check package
        run: |
          twine check dist/*

      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-artifacts
          path: dist/

  # Job 8: Deploy to staging (main branch only)
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: staging

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v3
        with:
          name: build-artifacts
          path: dist/

      - name: Deploy to staging
        run: |
          echo "üöÄ Deploying to staging environment..."
          echo "Build artifacts ready for deployment"
          # Add actual deployment steps here

      - name: Run smoke tests on staging
        run: |
          echo "üß™ Running smoke tests on staging..."
          # Add actual smoke test calls here
